//! Shortcuts that span lexer/parser abstraction.
//!
//! The way Rust works, parser doesn't necessary parse text, and you might
//! tokenize text without parsing it further. So, it makes sense to keep
//! abstract token parsing, and string tokenization as completely separate
//! layers.
//!
//! However, often you do parse text into syntax trees and the glue code for
//! that needs to live somewhere. Rather than putting it to lexer or parser, we
//! use a separate shortcuts module for that.

use std::mem;

use crate::{
    LexedStr, Step,
    SyntaxKind::{self, *},
};

#[derive(Debug)]
enum TriviaRegion {
    Keep(SyntaxKind),
    Replace(usize, SyntaxKind),
    RemoveAfter(usize, SyntaxKind),
    Remove(usize),
}

#[derive(Debug)]
pub enum StrStep<'a> {
    Token { kind: SyntaxKind, text: &'a str },
    Enter { kind: SyntaxKind },
    Exit,
    Error { msg: &'a str, pos: usize },
}

impl LexedStr<'_> {
    /// Eat newlines comments and whitespace given a starting token index
    /// Return the token index of the next non-whitespace token
    fn eat_newlines(&self, i: usize) -> usize {
        for ii in i..self.len() {
            match self.kind(ii) {
                EOL | COMMENT | WHITESPACE | PRE_ANNOTATION | POST_ANNOTATION => (),
                _ => return ii,
            }
        }

        self.len()
    }

    /// Compute the number of trivias at a point 'i'.
    /// Some trivias may be reduced into a 'psuedo' token, return the psuedo token
    /// as the second option in the tuple.
    fn as_trivia(&self, i: usize) -> TriviaRegion {
        assert!(i < self.len());

        let mut skip = 0;
        while skip + i < self.len() {
            match self.kind(i + skip) {
                WHITESPACE => {
                    skip += 1;
                }
                EOL | COMMENT | PRE_ANNOTATION | POST_ANNOTATION => {
                    let after = self.eat_newlines(i + skip + 1);
                    return match self.kind(i) {
                        RIGHT_PAREN | RIGHT_CURLY | RIGHT_SQUARE => {
                            // Whitespace behind these closing tokens are dropped
                            TriviaRegion::Remove(after - i)
                        }
                        _ => {
                            // This is actually a newline delimiter
                            TriviaRegion::Replace(after - i, EOL)
                        }
                    }
                }

                // Tokens that eat newlines after them
                STAR | RIGHT_ARROW | SLASH | MINUS | PLUS | EQUALS | SEMI | COMMA | COLON
                | LEFT_PAREN | LEFT_CURLY | LEFT_SQUARE => {
                    if skip > 0 {
                        return TriviaRegion::Remove(skip);
                    }

                    let after = self.eat_newlines(i + 1);
                    return TriviaRegion::RemoveAfter(after - i - 1, self.kind(i))
                }

                k if skip == 0 => {
                    return TriviaRegion::Keep(k)
                },
                _ => {
                    return TriviaRegion::Remove(skip)
                }
            }
        }

        assert!(skip > 0);
        TriviaRegion::Remove(skip)
    }

    pub fn to_input(&self) -> crate::Input {
        let mut res = crate::Input::with_capacity(self.len());
        let mut i = 0;
        while i < self.len() {
            let t = self.as_trivia(i);
            match t {
                TriviaRegion::Keep(k) => {
                    // Normal token
                    res.push(k);
                    i += 1;
                }
                TriviaRegion::Replace(n, token) => {
                    res.push(token);
                    i += n;
                }
                TriviaRegion::RemoveAfter(n, token) => {
                    res.push(token);
                    i += n + 1;
                }
                TriviaRegion::Remove(n) => {
                    i += n;
                }
            }
        }

        res
    }

    /// NB: only valid to call with Output from Reparser/TopLevelEntry.
    pub fn intersperse_trivia(
        &self,
        output: &crate::Output,
        sink: &mut dyn FnMut(StrStep<'_>),
    ) -> bool {
        let mut builder = Builder {
            lexed: self,
            pos: 0,
            state: State::PendingEnter,
            sink,
        };

        for event in output.iter() {
            match event {
                Step::Token {
                    kind,
                    n_input_tokens: n_raw_tokens,
                } => builder.token(kind, n_raw_tokens),
                Step::Enter { kind } => builder.enter(kind),
                Step::Exit => builder.exit(),
                Step::Error { msg } => {
                    let text_pos = builder.lexed.text_start(builder.pos);
                    (builder.sink)(StrStep::Error { msg, pos: text_pos });
                }
            }
        }

        match mem::replace(&mut builder.state, State::Normal) {
            State::PendingExit => {
                builder.eat_trivias();
                (builder.sink)(StrStep::Exit);
            }
            State::PendingEnter | State::Normal => unreachable!(),
        }

        // is_eof?
        builder.pos == builder.lexed.len()
    }
}

struct Builder<'a, 'b> {
    lexed: &'a LexedStr<'a>,
    pos: usize,
    state: State,
    sink: &'b mut dyn FnMut(StrStep<'_>),
}

enum State {
    PendingEnter,
    Normal,
    PendingExit,
}

impl Builder<'_, '_> {
    fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {
        match mem::replace(&mut self.state, State::Normal) {
            State::PendingEnter => unreachable!(),
            State::PendingExit => (self.sink)(StrStep::Exit),
            State::Normal => (),
        }

        let t = self.lexed.as_trivia(self.pos);

        match t {
            TriviaRegion::Keep(t_kind) => {
                assert_eq!(kind, t_kind);
                self.do_token(kind, n_tokens as usize);
            }
            TriviaRegion::Replace(n, t_kind) => {
                assert_eq!(kind, t_kind);
                assert_eq!(n_tokens, 1);
                self.do_token(kind, n);
            }
            TriviaRegion::RemoveAfter(n, t_kind) => {
                assert_eq!(kind, t_kind);
                assert_eq!(n_tokens, 1);
                self.do_token(kind, 1);

                for _ in 0..n {
                    let kind = self.lexed.kind(self.pos);
                    self.do_token(kind, 1);
                }
            }
            TriviaRegion::Remove(n) => {
                for _ in 0..n {
                    self.do_token(self.lexed.kind(self.pos), 1);
                }

                self.token(kind, n_tokens);
            }
        }
    }

    fn enter(&mut self, kind: SyntaxKind) {
        match mem::replace(&mut self.state, State::Normal) {
            State::PendingEnter => {
                (self.sink)(StrStep::Enter { kind });
                // No need to attach trivias to previous node: there is no
                // previous node.
                return;
            }
            State::PendingExit => (self.sink)(StrStep::Exit),
            State::Normal => (),
        }

        self.eat_whitespace_outer();
        (self.sink)(StrStep::Enter { kind });
        self.eat_whitespace_inner();
    }

    fn exit(&mut self) {
        match mem::replace(&mut self.state, State::PendingExit) {
            State::PendingEnter => unreachable!(),
            State::PendingExit => (self.sink)(StrStep::Exit),
            State::Normal => (),
        }
    }

    fn eat_trivias(&mut self) {
        if self.pos >= self.lexed.len() {
            return;
        }

        match self.lexed.as_trivia(self.pos) {
            TriviaRegion::Remove(n) => {
                for _ in 0..n {
                    let kind = self.lexed.kind(self.pos);
                    self.do_token(kind, 1);
                }
            }
            _ => {}
        }
    }

    fn eat_whitespace_outer(&mut self) {
        loop {
            let kind = self.lexed.kind(self.pos);
            match kind {
                WHITESPACE | EOL | COMMENT => {
                    self.do_token(kind, 1);
                }
                _ => break,
            }
        }
    }

    fn eat_whitespace_inner(&mut self) {
        loop {
            let kind = self.lexed.kind(self.pos);
            match kind {
                WHITESPACE | EOL | PRE_ANNOTATION | POST_ANNOTATION => {
                    self.do_token(kind, 1);
                }
                _ => break,
            }
        }
    }

    fn do_token(&mut self, kind: SyntaxKind, n_tokens: usize) {
        let text = &self.lexed.range_text(self.pos..self.pos + n_tokens);
        self.pos += n_tokens;
        (self.sink)(StrStep::Token { kind, text });
    }
}

// fn n_attached_trivias<'a>(
//     kind: SyntaxKind,
//     trivias: impl Iterator<Item = (SyntaxKind, &'a str)>,
// ) -> usize {
//     if kind.is_def() || kind.is_spec() {
//         let mut res = 0;
//         let mut trivias = trivias.enumerate().peekable();
//
//         while let Some((i, (kind, _))) = trivias.next() {
//             match kind {
//                 // TODO(tumbar) Take another look at this
//                 COMMENT | WHITESPACE | PRE_ANNOTATION => {
//                     res = i + 1;
//                 }
//                 POST_ANNOTATION => break,
//                 _ => (),
//             }
//         }
//         res
//     } else {
//         0
//     }
// }
